{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "# ENST00000267116.8-chr12:56239880-56239973\n",
    "# hg38\n",
    "# mammal\n",
    "# mammal\n",
    "# 0\n",
    "# 0\n",
    "# 3\n",
    "# 0\n",
    "# VFLGVEGLRRAYLPLQPQPWPLFLPHPYPF\n",
    "# 17\n",
    "# ENST00000307714.12+chr1:32036957-32038075\n",
    "# hg38\n",
    "# mammal\n",
    "# mammal\n",
    "# 0\n",
    "# 0\n",
    "# 3\n",
    "# 1\n",
    "# LNGVPEPSRGRGVPVRGRGAAPPPPPVPRGRGVGPPRGALVRGTPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150d1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = \"/home/user/data3/lit/project/sORFs/05-denovo-status/analysis/in_house_human_brain_denovo_check_20250410/results_120/prank/ENST00000267116.8-chr12__56239880-56239973.maf.best.anc.dnd\" #prot tree best.anc.dnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327e0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = \"/home/user/data3/lit/project/sORFs/05-denovo-status/analysis/in_house_human_brain_denovo_check_20250410/results_120/prank/ENST00000307714.12+chr1__32036957-32038075.maf.best.anc.dnd\" #prot tree best.anc.dnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dcb8a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/BGM/lit/.local/lib/python3.9/site-packages/Bio/Seq.py:2979: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panTro5': ['#38#', []], 'gorGor5': ['#61#', []], 'ponAbe2': ['#76#', []], 'nomLeu3': ['#84#', []], 'rheMac8': ['#92#', ['#2#', '#39#', '#3#', '#40#', '#62#', '#77#', '#4#', '#41#', '#5#', '#63#', '#85#']], 'calJac3': ['#97#', ['#6#', '#42#']], 'tarSyr2': ['#101#', []], 'otoGar3': ['#105#', ['#7#', '#43#']], 'galVar1': ['#108#', []], 'tupChi1': ['#111#', []], 'jacJac1': ['#114#', ['#8#', '#44#', '#64#', '#9#', '#45#', '#65#', '#78#', '#86#', '#93#', '#98#', '#10#', '#102#', '#11#', '#12#', '#46#', '#66#', '#106#', '#13#', '#109#', '#14#', '#112#']], 'vicPac2': ['#115#', ['#15#', '#47#', '#67#', '#16#', '#48#', '#68#', '#79#', '#17#', '#87#', '#18#', '#19#', '#49#', '#69#', '#20#', '#50#', '#70#', '#80#', '#21#', '#88#', '#94#', '#99#', '#103#', '#22#', '#51#', '#71#', '#23#', '#24#', '#52#', '#25#', '#26#', '#53#', '#27#', '#28#', '#54#', '#72#', '#81#', '#89#', '#95#', '#29#', '#100#', '#104#', '#30#', '#55#', '#31#', '#73#', '#32#', '#56#', '#74#', '#82#', '#90#', '#96#', '#107#', '#110#', '#33#', '#57#', '#113#']], 'loxAfr3': ['#116#', ['#34#', '#58#', '#35#', '#59#', '#75#', '#83#', '#36#', '#91#']], 'monDom5': ['#117#', ['#37#', '#60#']], 'ornAna2': ['#118#', []]}\n",
      "panTro5 #38# hominoid\n",
      "gorGor5 #61# hominoid\n",
      "ponAbe2 #76# hominoid\n",
      "nomLeu3 #84# hominoid\n",
      "rheMac8 #92# catarrhini\n",
      "calJac3 #97# simiiformes\n",
      "tarSyr2 #101# primates\n",
      "otoGar3 #105# primates\n",
      "galVar1 #108# primatomorpha\n",
      "tupChi1 #111# euarchontoglires\n",
      "jacJac1 #114# euarchontoglires\n",
      "vicPac2 #115# boreoeutheria\n",
      "loxAfr3 #116# placentalia\n",
      "monDom5 #117# mammal\n",
      "ornAna2 #118# mammal\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os.path\n",
    "\n",
    "# assign each species to the lineage\n",
    "order = {}\n",
    "for sp in (\"panTro5\",\"panPan2\",\"gorGor5\",\"ponAbe2\",\"nomLeu3\"):\n",
    "\torder[sp] = \"hominoid\"\n",
    "for sp in (\"rheMac8\",\"macFas5\",\"macNem1\",\"papAnu3\",\"manLeu1\",\"cerAty1\",\"chlSab2\",\"nasLar1\",\"rhiRox1\",\"rhiBie1\",\"colAng1\",\"HLpilTep1\"):\n",
    "\torder[sp] = \"catarrhini\"\n",
    "for sp in (\"calJac3\",\"aotNan1\",\"saiBol1\",\"cebCap1\"):\n",
    "\torder[sp] = \"simiiformes\"\n",
    "for sp in (\"tarSyr2\",\"otoGar3\",\"micMur3\",\"proCoq1\"):\n",
    "\torder[sp] = \"primates\"\n",
    "for sp in (\"galVar1\",):\n",
    "\torder[sp] = \"primatomorpha\"\t\n",
    "for sp in (\"tupChi1\",\"jacJac1\",\"micOch1\",\"criGri1\",\"mesAur1\",\"perManBai1\",\"mm10\",\"HLmusCar1\",\"HLmusPah1\",\"rn6\",\"HLmerUng1\",\"nanGal1\",\"HLcasCan1\",\"HLdipOrd2\",\"hetGla2\",\"HLfukDam1\",\"cavPor3\",\"chiLan1\",\"octDeg1\",\"speTri2\",\"HLmarMar1\",\"oryCun2\",\"ochPri3\"): #rodents+primates\n",
    "\torder[sp] = \"euarchontoglires\"\n",
    "\n",
    "cetartiodactyla =(\"vicPac2\",\"HLcamFer2\",\"HLcamBac1\",\"HLcamDro1\",\"HLturTru3\",\"HLorcOrc1\",\"HLdelLeu1\",\"lipVex1\",\"phyCat1\",\"balAcu1\",\"HLbalMys1\",\"bosTau8\",\"HLbosInd1\",\"bisBis1\",\"bosMut1\",\"bubBub1\",\"HLoviAri4\",\"HLoviCan1\",\"HLcapHir2\",\"panHod1\",\"HLodoVir1\",\"HLcerEla1\",\"susScr11\")\n",
    "perissodactyla = (\"HLequCab3\",\"equPrz1\",\"HLequAsi1\",\"cerSim1\")\n",
    "ferae = (\"felCat8\",\"HLaciJub1\",\"panTig1\",\"HLpanPar1\",\"canFam3\",\"HLlycPic1\",\"musFur1\",\"HLenhLut1\",\"HLailFul1\",\"ailMel1\",\"ursMar1\",\"odoRosDiv1\",\"lepWed1\",\"neoSch1\",\"manPen1\",\"HLmanJav1\")\n",
    "chiroptera = (\"pteAle1\",\"HLpteVam2\",\"rouAeg1\",\"HLrhiSin1\",\"HLhipArm1\",\"eptFus1\",\"myoDav1\",\"myoBra1\",\"myoLuc2\",\"HLminNat1\",\"HLdesRot1\")\n",
    "eulipotyphla = (\"eriEur2\",\"sorAra2\",\"conCri1\")\n",
    "boreoeutheria = cetartiodactyla + perissodactyla + ferae + chiroptera + eulipotyphla\n",
    "\n",
    "for sp in boreoeutheria: #previous+euarchontoglires\n",
    "\torder[sp] = \"boreoeutheria\"\n",
    "for sp in (\"loxAfr3\",\"triMan1\",\"HLproCap2\",\"chrAsi1\",\"echTel2\",\"eleEdw1\",\"oryAfe1\",\"dasNov3\",\"HLchoHof2\"): #atlantogenata +boro\n",
    "\torder[sp] = \"placentalia\"\n",
    "for sp in (\"monDom5\",\"sarHar1\",\"HLphaCin1\",\"ornAna2\"): #nonplacental+rest\n",
    "\torder[sp] = \"mammal\"\n",
    "\n",
    "# main\n",
    "fastan = tree.replace(\".dnd\",\".fas\")\n",
    "name = tree.split(\"/\")[-1].replace(\".maf.best.anc.dnd\",\"\")\n",
    "tag = tree.replace(\".maf.best.anc.dnd\",\"\")\n",
    "\n",
    "# generate ancestral protein\n",
    "fastap = open(tree.replace(\".dnd\",\".prot.fas\"),\"w+\")\n",
    "fa = {}\n",
    "fan = SeqIO.index(fastan, \"fasta\")\n",
    "for n in fan:\n",
    "\tfa[n] = str(Seq(str(fan[n].seq).replace(\"-\",\"\")).translate(cds = False))\n",
    "\tfastap.write(\">\" + n + \"\\n\" + fa[n] + \"\\n\")\n",
    "fastap.close()\n",
    "\n",
    "fline=open(tree).readline().rstrip().split(\")\")\n",
    "last_sp = \"hg38\"\n",
    "sub = 0\n",
    "ancestor ={}\n",
    "for n,line in enumerate(fline):\n",
    "\tif sub != 0:\n",
    "\t\tsub = sub - 1\n",
    "\t\tif not last_sp in ancestor:\n",
    "\t\t\tancestor[last_sp] = [\"none\",[]]\n",
    "\t\tancestor[last_sp][1].append(line.split(\":\")[0])\n",
    "\telse:\n",
    "\t\tif last_sp != \"hg38\":\n",
    "\t\t\tif not last_sp in ancestor:\n",
    "\t\t\t\tancestor[last_sp] = [\"none\",[]]\n",
    "\t\t\tancestor[last_sp][0] = line.split(\":\")[0]\n",
    "\t\ttry:\n",
    "\t\t\tlast_sp = line.split(\",\")[1].split(\":\")[0].replace(\"(\",\"\")\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tif n != 0:\n",
    "\t\tsub = sub + line.count(\"(\")\n",
    "# print species and ancestor tree\n",
    "print(ancestor)\n",
    "\n",
    "prot_ancestors_file = tag + \".prot.ancestors\"\n",
    "ancestors_file = tag + \".ancestors\"\n",
    "nucl_ancestors_file = tag + \".nucl.ancestors\"\n",
    "# 检查并删除已存在的文件\n",
    "if os.path.exists(prot_ancestors_file):\n",
    "    os.remove(prot_ancestors_file)\n",
    "if os.path.exists(ancestors_file):\n",
    "    os.remove(ancestors_file)\n",
    "if os.path.exists(nucl_ancestors_file):\n",
    "    os.remove(nucl_ancestors_file)\n",
    "# 打开文件进行写入\n",
    "outp = open(prot_ancestors_file, \"a+\")\n",
    "outh = open(ancestors_file, \"a+\")\n",
    "outn = open(nucl_ancestors_file, \"a+\")\n",
    "# 初始化变量\n",
    "max_st_cons = \"human\"\n",
    "max_sy_cons = \"human\"\n",
    "outp.write('orf_id\\tsp\\tev_age\\tsyn_age\\tbranch\\tTIS\\tmaxORF\\tconv\\tseq\\n')\n",
    "outh.write('orf_id\\tsp\\tev_age\\tsyn_age\\tgained\\tgained_convergent\\tlost\\tdenovo\\tseq\\n')\n",
    "\n",
    "# ORF structure\n",
    "## 进化上是否存在\n",
    "ev = {}\n",
    "## 最大的重叠比例\n",
    "max_op ={}\n",
    "## 起始密码子\n",
    "tis={}\n",
    "al_scodon = [\"ATG\", \"CTG\", \"ACG\", \"GTG\", \"TTG\", \"ATA\", \"ATC\", \"ATT\", \"AAG\", \"AGG\"]\n",
    "\n",
    "# estimate the presence of intact ORF\n",
    "for last_sp in ancestor:\n",
    "    tis[last_sp] = \"0\"\n",
    "    old_anc = ancestor[last_sp][0]\n",
    "    if len(str(fa[old_anc]).replace(\"-\",\"\").replace(\"X\",\"*\")) >= 4:\n",
    "        # 看是否在第一个位置或者下游的两个位置有非经典的起始密码子\n",
    "        first_scodon=str(fan[old_anc].seq).replace(\"-\",\"\")[0:3].upper()\n",
    "        second_codon=str(fan[old_anc].seq).replace(\"-\",\"\")[3:6].upper()\n",
    "        third_codon=str(fan[old_anc].seq).replace(\"-\",\"\")[6:9].upper()\n",
    "        if first_scodon in al_scodon or second_codon in al_scodon or third_codon in al_scodon:\n",
    "            tis[last_sp] = \"1\"\n",
    "        else:\n",
    "            tis[last_sp] = \"0\"\n",
    "    #Longest ORF in the stretch\n",
    "    op = -1\n",
    "    max_op[last_sp] = 0\n",
    "    if len(str(fa[old_anc]).replace(\"-\",\"\").replace(\"X\",\"*\")) >= 4:\n",
    "        first_scodon=str(fan[old_anc].seq).replace(\"-\",\"\")[0:3].upper()\n",
    "        for n2 in str(fa[old_anc]).replace(\"-\",\"\").replace(\"X\",\"*\"):\n",
    "            if (first_scodon in al_scodon) and (op == -1):\n",
    "                op = 1\n",
    "            elif n2 == \"*\":\n",
    "                if op > max_op[last_sp]:\n",
    "                    max_op[last_sp] = op\n",
    "                op = -1\n",
    "            elif op != -1:\n",
    "                op += 1\n",
    "        if op > max_op[last_sp]:\n",
    "            max_op[last_sp] = op\n",
    "        try:\n",
    "            max_op[last_sp] = float(max_op[last_sp])/len(str(fa[\"hg38\"]).replace(\"-\",\"\").replace(\"X\",\"\").replace(\"*\",\"\"))*100\n",
    "        except:\n",
    "            pass\n",
    "    # >= 70% of the sequence did not contain stop condons truncating the ORF and a conserved ATG start condon\n",
    "    if (max_op[last_sp] >= 70) and (int(tis[last_sp]) >= 1):\n",
    "        max_st_cons = order[last_sp]\n",
    "        ev[last_sp] = \"FIXED\"\n",
    "    # stop condons truncating the ORF resulting in < 70% of the ORF\n",
    "    else:\n",
    "        ev[last_sp] = \"ABSENT\"\n",
    "        \n",
    "    max_sy_cons = order[last_sp]\n",
    "\n",
    "# ortholog beyond intact ORF\n",
    "beyond = 0\n",
    "# whether is a de novo ORF\n",
    "denovo = 0\n",
    "# 分别代表gained gained_convergent lost\n",
    "count  = [0,0,0]\n",
    "for last_sp in ancestor:\n",
    "    old_anc = ancestor[last_sp][0]\n",
    "    print(last_sp,old_anc,order[last_sp])\n",
    "    # if ancestral ortholog beyond intact ORF\n",
    "    if beyond == 1:\n",
    "        denovo = 1\n",
    "    if (order[last_sp] == max_st_cons) or (max_st_cons == \"human\"):\n",
    "        beyond = 1\n",
    "\n",
    "    # Check if ORF is present in some intermediate branch\n",
    "    # for each species in intermediate branch (sp2)\n",
    "    for sp2 in ancestor[last_sp][1]:\n",
    "        tis2 = \"0\"\n",
    "        if len(str(fa[sp2]).replace(\"-\",\"\").replace(\"X\",\"*\")) >= 4:\n",
    "            # 看是否在第一个位置或者下游的两个位置有非经典的起始密码子\n",
    "            first_scodon=str(fan[sp2].seq).replace(\"-\",\"\")[0:3].upper()\n",
    "            second_codon=str(fan[sp2].seq).replace(\"-\",\"\")[3:6].upper()\n",
    "            third_codon=str(fan[sp2].seq).replace(\"-\",\"\")[6:9].upper()\n",
    "            if first_scodon in al_scodon or second_codon in al_scodon or third_codon in al_scodon:\n",
    "                tis2 = \"1\"\n",
    "            else:\n",
    "                tis2 = \"0\"\n",
    "\n",
    "        #Longest ORF in the stretch\n",
    "        op = -1\n",
    "        max_op2 = 0\n",
    "        for n2 in str(fa[sp2]).replace(\"-\",\"\").replace(\"X\",\"*\"):\n",
    "            first_scodon=str(fan[old_anc].seq).replace(\"-\",\"\")[0:3].upper()\n",
    "            if (first_scodon in al_scodon) and (op == -1):\n",
    "                op = 1\n",
    "            if n2 == \"*\":\n",
    "                op = -1\n",
    "            elif op != -1:\n",
    "                op += 1\n",
    "        if op > max_op2:\n",
    "            max_op2 = op\n",
    "        try:\n",
    "            max_op2 = float(max_op2)/len(str(fa[\"hg38\"]).replace(\"-\",\"\").replace(\"X\",\"\").replace(\"*\",\"\"))*100\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if (max_op2 >= 70) and (int(tis2) >= 1):\n",
    "            if ev[last_sp] == \"ABSENT\":\n",
    "                ev[last_sp] = \"GAINED\"\n",
    "                count[0] += 1\n",
    "                if beyond == 1:\n",
    "                    count[1] += 1\n",
    "        else:\n",
    "            if ev[last_sp] == \"FIXED\":\n",
    "                ev[last_sp] = \"LOST\"\n",
    "                count[2] += 1\n",
    "\n",
    "        # estimate the conservation of the ortholog peptide sequences\n",
    "\n",
    "    #Write output\n",
    "    l = name + \"\\t\" + last_sp + \"\\t\" + order[last_sp] + \"\\t\" + order[last_sp] + \"\\t\" + old_anc + \"\\t\" + str(tis[last_sp]) + \"\\t\" + str(max_op[last_sp]) + \"\\t\" + ev[last_sp] + \"\\t\" + str(fa[old_anc]).replace(\"-\",\"\").replace(\"X\",\"*\") + \"\\n\"\n",
    "    outp.write(l.replace(\"W\\n\",\"\\n\"))\n",
    "    outn.write(\">\" + name + \"--\" + last_sp + \"\\n\" + str(fan[old_anc].seq) + \"\\n\")\n",
    "\n",
    "\n",
    "outh.write(name + \"\\thg38\\t\" + str(max_st_cons) + \"\\t\" + str(max_sy_cons) + \"\\t\" + str(count[0]) + \"\\t\" + str(count[1]) + \"\\t\" + str(count[2]) + \"\\t\" + str(denovo) + \"\\t\" + str(fa[\"hg38\"]).replace(\"-\",\"\").replace(\"X\",\"\") + \"\\n\")\n",
    "\n",
    "outn.write(\">\" + name + \"--hg38\\n\" + str(fan[\"hg38\"].seq) + \"\\n\")\n",
    "\n",
    "outp.close()\n",
    "outn.close()\n",
    "outh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b46e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "990057c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mammal mammal\n"
     ]
    }
   ],
   "source": [
    "print(max_st_cons,max_sy_cons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denovo",
   "language": "python",
   "name": "denovo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
